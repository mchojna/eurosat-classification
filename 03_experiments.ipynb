{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581e0cb8",
   "metadata": {},
   "source": [
    "# EuroSAT CNN Architecture Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a557270",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d0607",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cab957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eurosat_dataset(data_dir=\"data\"):\n",
    "    data_path = Path(data_dir)\n",
    "\n",
    "    # Get all class directories\n",
    "    class_dirs = [d for d in data_path.iterdir() if d.is_dir()]\n",
    "    class_names = sorted([d.name for d in class_dirs])\n",
    "\n",
    "    print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load images from each class\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = data_path / class_name\n",
    "        image_files = list(class_path.glob(\"*.jpg\")) + list(class_path.glob(\"*.png\"))\n",
    "\n",
    "        print(f\"Loading {len(image_files)} images from {class_name}...\")\n",
    "\n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                # Load image\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Store image and label\n",
    "                images.append(img_array)\n",
    "                labels.append(class_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    data = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"\\nDataset loaded successfully!\")\n",
    "    print(f\"Total images           : {len(data)}\")\n",
    "    print(f\"Data shape             : {data.shape}\")\n",
    "    print(f\"Labels shape           : {labels.shape}\")\n",
    "\n",
    "    return data, labels, class_names\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data, labels, class_names = load_eurosat_dataset(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6333df",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "X = data.astype(\"float32\") / 255.0\n",
    "y = labels\n",
    "\n",
    "print(f\"Data shape             : {X.shape}\")\n",
    "print(f\"Data dtype             : {X.dtype}\")\n",
    "print(f\"Data range             : [{X.min():.2f}, {X.max():.2f}]\")\n",
    "print(f\"Number of classes      : {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b93b2",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d634af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.13, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set size      : {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size    : {X_val.shape[0]} samples\")\n",
    "print(f\"Test set size          : {X_test.shape[0]} samples\")\n",
    "print(f\"Image shape            : {X_train.shape[1:]}\")\n",
    "print(f\"Number of classes      : {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51169e4c",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseF1Score(keras.metrics.Metric):\n",
    "    \"\"\"F1 Score metric that works with sparse (integer) labels.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, average=\"weighted\", name=\"f1_score\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.f1_metric = keras.metrics.F1Score(average=average)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert sparse labels to one-hot encoding\n",
    "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), self.num_classes)\n",
    "        self.f1_metric.update_state(y_true_one_hot, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1_metric.result()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.f1_metric.reset_state()\n",
    "\n",
    "\n",
    "class F1Callback(keras.callbacks.Callback):\n",
    "    \"\"\"Callback to track F1 score during training for early stopping.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_f1 = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_f1 = logs.get(\"val_f1_score\")\n",
    "        if val_f1 and val_f1 > self.best_f1:\n",
    "            self.best_f1 = val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6684b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model, X_train, X_val, y_train, y_val, model_name, epochs=20, batch_size=32\n",
    "):\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "    # Early stopping on validation F1 score\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_f1_score\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1,\n",
    "    )\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # Predict on validation set\n",
    "    start_time = time.time()\n",
    "    y_pred_probs = model.predict(X_val, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    predict_time = time.time() - start_time\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_val, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nTraining time          : {train_time:.2f} seconds\")\n",
    "    print(f\"Prediction time        : {predict_time:.2f} seconds\")\n",
    "\n",
    "    print(f\"\\nValidation Set Performance Metrics:\")\n",
    "    print(f\"  Accuracy             : {accuracy:.4f}\")\n",
    "    print(f\"  Precision            : {precision:.4f}\")\n",
    "    print(f\"  Recall               : {recall:.4f}\")\n",
    "    print(f\"  F1-Score             : {f1:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=class_names))\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"model_name\": model_name,\n",
    "        \"history\": history,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"train_time\": train_time,\n",
    "        \"predict_time\": predict_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9495c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_val, y_pred, class_names, model_name):\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        cbar_kws={\"label\": \"Number of samples\"},\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"True Label\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def plot_training_curves(history, model_name):\n",
    "    \"\"\"Plot loss and F1 score curves for a model.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Loss curves\n",
    "    axes[0].plot(history.history[\"loss\"], label=\"Train Loss\", linewidth=2)\n",
    "    axes[0].plot(history.history[\"val_loss\"], label=\"Val Loss\", linewidth=2)\n",
    "    axes[0].set_xlabel(\"Epoch\", fontsize=12, fontweight=\"bold\")\n",
    "    axes[0].set_ylabel(\"Loss\", fontsize=12, fontweight=\"bold\")\n",
    "    axes[0].set_title(f\"Loss Curves - {model_name}\", fontsize=13, fontweight=\"bold\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    # F1 score curves\n",
    "    axes[1].plot(history.history[\"f1_score\"], label=\"Train F1\", linewidth=2)\n",
    "    axes[1].plot(history.history[\"val_f1_score\"], label=\"Val F1\", linewidth=2)\n",
    "    axes[1].set_xlabel(\"Epoch\", fontsize=12, fontweight=\"bold\")\n",
    "    axes[1].set_ylabel(\"F1 Score\", fontsize=12, fontweight=\"bold\")\n",
    "    axes[1].set_title(f\"F1 Score Curves - {model_name}\", fontsize=13, fontweight=\"bold\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf73866",
   "metadata": {},
   "source": [
    "## Experiment 1: Network Depth\n",
    "\n",
    "In this experiment, we investigate the optimal depth of the CNN by varying the number of Conv2D + MaxPooling blocks. \n",
    "\n",
    "We test architectures with **2, 3, and 4** Conv2D + MaxPooling blocks. Each configuration has:\n",
    "- **ELU activation** function\n",
    "- **He initialization** for weights\n",
    "- **Batch Normalization** before and after each convolutional layer\n",
    "- **Early stopping** on validation F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_depth_model(\n",
    "    num_blocks, num_classes, input_shape=(64, 64, 3), base_filters=16\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a CNN with variable depth (number of Conv2D + MaxPooling blocks).\n",
    "    Uses ELU activation, He initialization, and Batch Normalization.\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of Conv2D + MaxPooling blocks (2-5)\n",
    "        num_classes: Number of output classes\n",
    "        input_shape: Shape of input images\n",
    "        base_filters: Number of filters (constant across all blocks)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=f\"depth_model_{num_blocks}_blocks\")\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "    for block in range(num_blocks):\n",
    "        # Batch Normalization before Conv2D\n",
    "        model.add(layers.BatchNormalization(name=f\"block{block+1}_bn_pre\"))\n",
    "\n",
    "        # Conv2D layer with ELU activation and He initialization\n",
    "        model.add(\n",
    "            layers.Conv2D(\n",
    "                base_filters,\n",
    "                (3, 3),\n",
    "                activation=\"elu\",\n",
    "                padding=\"same\",\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                name=f\"block{block+1}_conv\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Batch Normalization after Conv2D\n",
    "        model.add(layers.BatchNormalization(name=f\"block{block+1}_bn_post\"))\n",
    "\n",
    "        # MaxPooling layer\n",
    "        model.add(layers.MaxPooling2D((2, 2), name=f\"block{block+1}_maxpool\"))\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_1\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_1_bn\"))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_2\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_2_bn\"))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[SparseF1Score(num_classes=num_classes, average=\"weighted\")],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81575fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different network depths (2-4 blocks)\n",
    "depth_configs = [2, 3, 4]\n",
    "depth_results = []\n",
    "\n",
    "for num_blocks in depth_configs:\n",
    "    print(f\"Testing CNN with {num_blocks} Conv2D + MaxPooling block(s)\")\n",
    "\n",
    "    # Build model\n",
    "    model = build_depth_model(num_blocks, len(class_names))\n",
    "\n",
    "    # Print architecture\n",
    "    print(f\"\\nArchitecture Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Train and evaluate\n",
    "    result = evaluate_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        X_val,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        f\"CNN Depth {num_blocks}\",\n",
    "        epochs=30,\n",
    "    )\n",
    "    result[\"num_blocks\"] = num_blocks\n",
    "    depth_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb69fce",
   "metadata": {},
   "source": [
    "### Experiment 1: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare depth experiment results in a table\n",
    "depth_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Blocks\": [r[\"num_blocks\"] for r in depth_results],\n",
    "        \"Model\": [r[\"model_name\"] for r in depth_results],\n",
    "        \"Val Accuracy\": [f\"{r['accuracy']:.4f}\" for r in depth_results],\n",
    "        \"Val Precision\": [f\"{r['precision']:.4f}\" for r in depth_results],\n",
    "        \"Val Recall\": [f\"{r['recall']:.4f}\" for r in depth_results],\n",
    "        \"Val F1-Score\": [f\"{r['f1']:.4f}\" for r in depth_results],\n",
    "        \"Train Time (s)\": [f\"{r['train_time']:.2f}\" for r in depth_results],\n",
    "        \"Predict Time (s)\": [f\"{r['predict_time']:.2f}\" for r in depth_results],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Experiment 1: Network Depth Results\")\n",
    "display(depth_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Experiment 1 results to CSV\n",
    "depth_summary.to_csv(\"results/esults_experiment1_depth.csv\", index=False)\n",
    "print(\"\\nResults saved to: results_experiment1_depth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdeed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize depth experiment results with metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "depth_blocks = [r[\"num_blocks\"] for r in depth_results]\n",
    "depth_f1 = [r[\"f1\"] for r in depth_results]\n",
    "depth_accuracy = [r[\"accuracy\"] for r in depth_results]\n",
    "depth_train_time = [r[\"train_time\"] for r in depth_results]\n",
    "\n",
    "# F1-Score vs Depth\n",
    "axes[0, 0].plot(\n",
    "    depth_blocks,\n",
    "    depth_f1,\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"Number of Blocks\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_ylabel(\"F1-Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_title(\"F1-Score vs Network Depth\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "axes[0, 0].set_xticks(depth_blocks)\n",
    "\n",
    "# Accuracy vs Depth\n",
    "axes[0, 1].plot(\n",
    "    depth_blocks,\n",
    "    depth_accuracy,\n",
    "    marker=\"s\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"green\",\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Number of Blocks\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_ylabel(\"Accuracy\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_title(\"Accuracy vs Network Depth\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "axes[0, 1].set_xticks(depth_blocks)\n",
    "\n",
    "# Training Time vs Depth\n",
    "axes[1, 0].bar(\n",
    "    depth_blocks,\n",
    "    depth_train_time,\n",
    "    color=\"coral\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Number of Blocks\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_ylabel(\"Training Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_title(\"Training Time vs Network Depth\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 0].grid(axis=\"y\", alpha=0.3)\n",
    "axes[1, 0].set_xticks(depth_blocks)\n",
    "\n",
    "# All metrics comparison\n",
    "x = np.arange(len(depth_blocks))\n",
    "width = 0.2\n",
    "axes[1, 1].bar(x - width, depth_accuracy, width, label=\"Accuracy\")\n",
    "axes[1, 1].bar(x, [r[\"precision\"] for r in depth_results], width, label=\"Precision\")\n",
    "axes[1, 1].bar(x + width, [r[\"recall\"] for r in depth_results], width, label=\"Recall\")\n",
    "axes[1, 1].set_xlabel(\"Number of Blocks\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_title(\"Metrics Comparison by Depth\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(depth_blocks)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for all depth configurations\n",
    "for result in depth_results:\n",
    "    print(f\"\\nTraining Curves for: {result['model_name']}\")\n",
    "    plot_training_curves(result[\"history\"], result[\"model_name\"])\n",
    "\n",
    "# Find best depth based on F1-Score\n",
    "best_depth_idx = np.argmax([r[\"f1\"] for r in depth_results])\n",
    "best_depth = depth_results[best_depth_idx][\"num_blocks\"]\n",
    "best_depth_f1 = depth_results[best_depth_idx][\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best network depth     : {best_depth} block(s)\")\n",
    "print(f\"Best F1-Score          : {best_depth_f1:.4f}\")\n",
    "print(f\"This depth will be used for Experiment 2 (Block Width).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afcb07",
   "metadata": {},
   "source": [
    "## Experiment 2: Block Width\n",
    "\n",
    "In this experiment, we investigate the optimal width of each block by varying the number of Conv2D layers within each block before the MaxPooling layer.\n",
    "\n",
    "Using the best depth from Experiment 1, we test architectures with **2, 3, and 4** Conv2D layers per block. All configurations use:\n",
    "- **ELU activation** function\n",
    "- **He initialization** for weights\n",
    "- **Batch Normalization** before and after each convolutional layer\n",
    "- **Early stopping** on validation F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_width_model(\n",
    "    num_blocks, convs_per_block, num_classes, input_shape=(64, 64, 3), base_filters=16\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a CNN with variable width (number of Conv2D layers per block).\n",
    "    Uses ELU activation, He initialization, and Batch Normalization.\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of blocks (Conv2D layers + MaxPooling)\n",
    "        convs_per_block: Number of Conv2D layers in each block before MaxPooling\n",
    "        num_classes: Number of output classes\n",
    "        input_shape: Shape of input images\n",
    "        base_filters: Number of filters (constant across all blocks)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=f\"width_model_{convs_per_block}_convs\")\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "    for block in range(num_blocks):\n",
    "        # Add multiple Conv2D layers per block\n",
    "        for conv in range(convs_per_block):\n",
    "            # Batch Normalization before Conv2D\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_pre\")\n",
    "            )\n",
    "\n",
    "            # Conv2D layer with ELU activation and He initialization\n",
    "            model.add(\n",
    "                layers.Conv2D(\n",
    "                    base_filters,\n",
    "                    (3, 3),\n",
    "                    activation=\"elu\",\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    name=f\"block{block+1}_conv{conv+1}\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Batch Normalization after Conv2D\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_post\")\n",
    "            )\n",
    "\n",
    "        # MaxPooling layer after all convs in the block\n",
    "        model.add(layers.MaxPooling2D((2, 2), name=f\"block{block+1}_maxpool\"))\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_1\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_1_bn\"))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_2\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_2_bn\"))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[SparseF1Score(num_classes=num_classes, average=\"weighted\")],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different block widths (2-4 Conv2D layers per block)\n",
    "width_configs = [2, 3, 4]\n",
    "width_results = []\n",
    "\n",
    "print(f\"Using best depth from Experiment 1: {best_depth} block(s)\")\n",
    "\n",
    "for convs_per_block in width_configs:\n",
    "    print(f\"Testing CNN with {convs_per_block} Conv2D layer(s) per block\")\n",
    "    print(\n",
    "        f\"Total blocks: {best_depth}, Total Conv2D layers: {best_depth * convs_per_block}\"\n",
    "    )\n",
    "\n",
    "    # Build model\n",
    "    model = build_width_model(best_depth, convs_per_block, len(class_names))\n",
    "\n",
    "    # Print architecture\n",
    "    print(f\"\\nArchitecture Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Train and evaluate\n",
    "    result = evaluate_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        X_val,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        f\"CNN Width {convs_per_block}\",\n",
    "        epochs=30,\n",
    "    )\n",
    "    result[\"convs_per_block\"] = convs_per_block\n",
    "    result[\"num_blocks\"] = best_depth\n",
    "    width_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a954a9c",
   "metadata": {},
   "source": [
    "### Experiment 2: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare width experiment results in a table\n",
    "width_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Convs/Block\": [r[\"convs_per_block\"] for r in width_results],\n",
    "        \"Model\": [r[\"model_name\"] for r in width_results],\n",
    "        \"Val Accuracy\": [f\"{r['accuracy']:.4f}\" for r in width_results],\n",
    "        \"Val Precision\": [f\"{r['precision']:.4f}\" for r in width_results],\n",
    "        \"Val Recall\": [f\"{r['recall']:.4f}\" for r in width_results],\n",
    "        \"Val F1-Score\": [f\"{r['f1']:.4f}\" for r in width_results],\n",
    "        \"Train Time (s)\": [f\"{r['train_time']:.2f}\" for r in width_results],\n",
    "        \"Predict Time (s)\": [f\"{r['predict_time']:.2f}\" for r in width_results],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Experiment 2: Block Width Results (using {best_depth} block(s))\")\n",
    "display(width_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Experiment 2 results to CSV\n",
    "width_summary.to_csv(\"results/results_experiment2_width.csv\", index=False)\n",
    "print(\"\\nResults saved to: results_experiment2_width.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2617c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize width experiment results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "width_convs = [r[\"convs_per_block\"] for r in width_results]\n",
    "width_f1 = [r[\"f1\"] for r in width_results]\n",
    "width_accuracy = [r[\"accuracy\"] for r in width_results]\n",
    "width_train_time = [r[\"train_time\"] for r in width_results]\n",
    "\n",
    "# F1-Score vs Width\n",
    "axes[0, 0].plot(\n",
    "    width_convs,\n",
    "    width_f1,\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"Conv2D Layers per Block\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_ylabel(\"F1-Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_title(\"F1-Score vs Block Width\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "axes[0, 0].set_xticks(width_convs)\n",
    "\n",
    "# Accuracy vs Width\n",
    "axes[0, 1].plot(\n",
    "    width_convs,\n",
    "    width_accuracy,\n",
    "    marker=\"s\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"green\",\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Conv2D Layers per Block\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_ylabel(\"Accuracy\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_title(\"Accuracy vs Block Width\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "axes[0, 1].set_xticks(width_convs)\n",
    "\n",
    "# Training Time vs Width\n",
    "axes[1, 0].bar(\n",
    "    width_convs,\n",
    "    width_train_time,\n",
    "    color=\"coral\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Conv2D Layers per Block\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_ylabel(\"Training Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_title(\"Training Time vs Block Width\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 0].grid(axis=\"y\", alpha=0.3)\n",
    "axes[1, 0].set_xticks(width_convs)\n",
    "\n",
    "# All metrics comparison\n",
    "x = np.arange(len(width_convs))\n",
    "width_bar = 0.2\n",
    "axes[1, 1].bar(x - width_bar, width_accuracy, width_bar, label=\"Accuracy\")\n",
    "axes[1, 1].bar(x, [r[\"precision\"] for r in width_results], width_bar, label=\"Precision\")\n",
    "axes[1, 1].bar(\n",
    "    x + width_bar, [r[\"recall\"] for r in width_results], width_bar, label=\"Recall\"\n",
    ")\n",
    "axes[1, 1].set_xlabel(\"Conv2D Layers per Block\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_title(\"Metrics Comparison by Width\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(width_convs)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for all width configurations\n",
    "for result in width_results:\n",
    "    print(f\"\\nTraining Curves for: {result['model_name']}\")\n",
    "    plot_training_curves(result[\"history\"], result[\"model_name\"])\n",
    "\n",
    "# Find best width based on F1-Score\n",
    "best_width_idx = np.argmax([r[\"f1\"] for r in width_results])\n",
    "best_width = width_results[best_width_idx][\"convs_per_block\"]\n",
    "best_width_f1 = width_results[best_width_idx][\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25827aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best block width       : {best_width} Conv2D layer(s) per block\")\n",
    "print(f\"Best F1-Score          : {best_width_f1:.4f}\")\n",
    "print(f\"This width will be used for Experiment 3 (Number of Filters).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bbbe3f",
   "metadata": {},
   "source": [
    "## Experiment 3: Number of Filters\n",
    "\n",
    "In this experiment, we investigate the impact of the number of filters in convolutional layers.\n",
    "\n",
    "Using the best depth and width from previous experiments, we test architectures with different base filter configurations: **16 and 32**. All configurations use:\n",
    "- **ELU activation** function\n",
    "- **He initialization** for weights  \n",
    "- **Batch Normalization** before and after each convolutional layer\n",
    "- **Early stopping** on validation F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e993cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filter_model(\n",
    "    num_blocks, convs_per_block, num_classes, base_filters, input_shape=(64, 64, 3)\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a CNN to test different filter configurations.\n",
    "    Uses ELU activation, He initialization, and Batch Normalization.\n",
    "    Doubles the number of filters after each MaxPooling layer.\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of blocks (Conv2D layers + MaxPooling)\n",
    "        convs_per_block: Number of Conv2D layers in each block before MaxPooling\n",
    "        num_classes: Number of output classes\n",
    "        base_filters: Number of filters in the first block\n",
    "        input_shape: Shape of input images\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=f\"filter_model_{base_filters}_filters\")\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "    for block in range(num_blocks):\n",
    "        # Calculate number of filters for this block (doubles after each pooling)\n",
    "        current_filters = base_filters * (2**block)\n",
    "\n",
    "        # Add multiple Conv2D layers per block\n",
    "        for conv in range(convs_per_block):\n",
    "            # Batch Normalization before Conv2D\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_pre\")\n",
    "            )\n",
    "\n",
    "            # Conv2D layer with ELU activation and He initialization\n",
    "            model.add(\n",
    "                layers.Conv2D(\n",
    "                    current_filters,\n",
    "                    (3, 3),\n",
    "                    activation=\"elu\",\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    name=f\"block{block+1}_conv{conv+1}\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Batch Normalization after Conv2D\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_post\")\n",
    "            )\n",
    "\n",
    "        # MaxPooling layer after all convs in the block\n",
    "        model.add(layers.MaxPooling2D((2, 2), name=f\"block{block+1}_maxpool\"))\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_1\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_1_bn\"))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_2\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_2_bn\"))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[SparseF1Score(num_classes=num_classes, average=\"weighted\")],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36401a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different filter configurations\n",
    "filter_configs = [16, 32]\n",
    "filter_results = []\n",
    "\n",
    "print(f\"Using best depth from Experiment 1: {best_depth} block(s)\")\n",
    "print(f\"Using best width from Experiment 2: {best_width} Conv2D layer(s) per block\")\n",
    "\n",
    "for base_filters in filter_configs:\n",
    "    print(f\"Testing CNN with base filters: {base_filters}\")\n",
    "\n",
    "    # Build model\n",
    "    model = build_filter_model(best_depth, best_width, len(class_names), base_filters)\n",
    "\n",
    "    # Print architecture\n",
    "    print(f\"\\nArchitecture Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Train and evaluate\n",
    "    result = evaluate_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        X_val,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        f\"CNN Filters {base_filters}\",\n",
    "        epochs=30,\n",
    "    )\n",
    "    result[\"base_filters\"] = base_filters\n",
    "    result[\"num_blocks\"] = best_depth\n",
    "    result[\"convs_per_block\"] = best_width\n",
    "    filter_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7437049",
   "metadata": {},
   "source": [
    "### Experiment 3: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare filter experiment results in a table\n",
    "filter_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Base Filters\": [r[\"base_filters\"] for r in filter_results],\n",
    "        \"Model\": [r[\"model_name\"] for r in filter_results],\n",
    "        \"Val Accuracy\": [f\"{r['accuracy']:.4f}\" for r in filter_results],\n",
    "        \"Val Precision\": [f\"{r['precision']:.4f}\" for r in filter_results],\n",
    "        \"Val Recall\": [f\"{r['recall']:.4f}\" for r in filter_results],\n",
    "        \"Val F1-Score\": [f\"{r['f1']:.4f}\" for r in filter_results],\n",
    "        \"Train Time (s)\": [f\"{r['train_time']:.2f}\" for r in filter_results],\n",
    "        \"Predict Time (s)\": [f\"{r['predict_time']:.2f}\" for r in filter_results],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Experiment 3: Number of Filters Results\")\n",
    "display(filter_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c50979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Experiment 3 results to CSV\n",
    "filter_summary.to_csv(\"results/results_experiment3_filters.csv\", index=False)\n",
    "print(\"\\nResults saved to: results_experiment3_filters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filter experiment results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "filter_bases = [r[\"base_filters\"] for r in filter_results]\n",
    "\n",
    "# F1-Score comparison\n",
    "axes[0, 0].plot(\n",
    "    filter_bases,\n",
    "    [r[\"f1\"] for r in filter_results],\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"Base Filters\", fontsize=12)\n",
    "axes[0, 0].set_ylabel(\"F1-Score\", fontsize=12)\n",
    "axes[0, 0].set_title(\"F1-Score vs Number of Filters\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_xticks(filter_bases)\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0, 1].plot(\n",
    "    filter_bases,\n",
    "    [r[\"accuracy\"] for r in filter_results],\n",
    "    marker=\"s\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"green\",\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Base Filters\", fontsize=12)\n",
    "axes[0, 1].set_ylabel(\"Accuracy\", fontsize=12)\n",
    "axes[0, 1].set_title(\"Accuracy vs Number of Filters\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_xticks(filter_bases)\n",
    "\n",
    "# Training time comparison\n",
    "axes[1, 0].bar(\n",
    "    range(len(filter_bases)), [r[\"train_time\"] for r in filter_results], color=\"coral\"\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Base Filters\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Training Time (s)\", fontsize=12)\n",
    "axes[1, 0].set_title(\n",
    "    \"Training Time vs Number of Filters\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "axes[1, 0].set_xticks(range(len(filter_bases)))\n",
    "axes[1, 0].set_xticklabels(filter_bases)\n",
    "axes[1, 0].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# All metrics comparison\n",
    "metrics_data = {\n",
    "    \"Precision\": [r[\"precision\"] for r in filter_results],\n",
    "    \"Recall\": [r[\"recall\"] for r in filter_results],\n",
    "    \"F1-Score\": [r[\"f1\"] for r in filter_results],\n",
    "}\n",
    "x = np.arange(len(filter_bases))\n",
    "width = 0.25\n",
    "\n",
    "for i, (metric_name, metric_values) in enumerate(metrics_data.items()):\n",
    "    axes[1, 1].bar(x + i * width, metric_values, width, label=metric_name)\n",
    "\n",
    "axes[1, 1].set_xlabel(\"Base Filters\", fontsize=12)\n",
    "axes[1, 1].set_ylabel(\"Score\", fontsize=12)\n",
    "axes[1, 1].set_title(\"All Metrics vs Number of Filters\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 1].set_xticks(x + width)\n",
    "axes[1, 1].set_xticklabels(filter_bases)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for all filters configurations\n",
    "for result in filter_results:\n",
    "    print(f\"\\nTraining Curves for: {result['model_name']}\")\n",
    "    plot_training_curves(result[\"history\"], result[\"model_name\"])\n",
    "\n",
    "# Find best filters based on F1-Score\n",
    "best_filter_idx = np.argmax([r[\"f1\"] for r in filter_results])\n",
    "best_filter = filter_results[best_filter_idx][\"base_filters\"]\n",
    "best_filter_f1 = filter_results[best_filter_idx][\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best base filters      : {best_filter}\")\n",
    "print(f\"Best F1-Score          : {best_filter_f1:.4f}\")\n",
    "print(f\"These base filters will be used for Experiment 4 (Dropout).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ce21e",
   "metadata": {},
   "source": [
    "## Experiment 4: Dropout Regularization\n",
    "\n",
    "In this experiment, we investigate the impact of dropout regularization on model performance.\n",
    "\n",
    "Using the optimal architecture from previous experiments, we test different dropout rates: **0.0 (no dropout), 0.2, 0.4, and 0.6**. Dropout is applied after each MaxPooling layer and after the Flatten layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dropout_model(\n",
    "    num_blocks,\n",
    "    convs_per_block,\n",
    "    num_classes,\n",
    "    dropout_rate=0.3,\n",
    "    input_shape=(64, 64, 3),\n",
    "    base_filters=32,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a CNN with dropout regularization.\n",
    "    Doubles the number of filters after each MaxPooling layer.\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of blocks\n",
    "        convs_per_block: Number of Conv2D layers per block\n",
    "        num_classes: Number of output classes\n",
    "        dropout_rate: Dropout rate (0.0 = no dropout)\n",
    "        input_shape: Shape of input images\n",
    "        base_filters: Base number of filters in the first block\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=f\"dropout_model_dr{dropout_rate}\")\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "    for block in range(num_blocks):\n",
    "        # Calculate number of filters for this block (doubles after each pooling)\n",
    "        current_filters = base_filters * (2**block)\n",
    "\n",
    "        for conv in range(convs_per_block):\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_pre\")\n",
    "            )\n",
    "            model.add(\n",
    "                layers.Conv2D(\n",
    "                    current_filters,\n",
    "                    (3, 3),\n",
    "                    activation=\"elu\",\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    name=f\"block{block+1}_conv{conv+1}\",\n",
    "                )\n",
    "            )\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_post\")\n",
    "            )\n",
    "\n",
    "        model.add(layers.MaxPooling2D((2, 2), name=f\"block{block+1}_maxpool\"))\n",
    "\n",
    "        # Dropout after MaxPooling\n",
    "        if dropout_rate > 0:\n",
    "            model.add(layers.Dropout(dropout_rate, name=f\"block{block+1}_dropout\"))\n",
    "\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "\n",
    "    # Dropout after Flatten\n",
    "    if dropout_rate > 0:\n",
    "        model.add(layers.Dropout(dropout_rate, name=\"flatten_dropout\"))\n",
    "\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_1\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_1_bn\"))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_2\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.BatchNormalization(name=\"dense_2_bn\"))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[SparseF1Score(num_classes=num_classes, average=\"weighted\")],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different dropout rates\n",
    "dropout_configs = [0.0, 0.2, 0.4, 0.6]\n",
    "dropout_results = []\n",
    "\n",
    "print(\n",
    "    f\"Using optimal architecture: {best_depth} blocks, {best_width} convs/block, {best_filter} base filters\"\n",
    ")\n",
    "\n",
    "for dropout_rate in dropout_configs:\n",
    "    print(f\"Testing CNN with dropout rate: {dropout_rate}\")\n",
    "\n",
    "    # Build model\n",
    "    model = build_dropout_model(\n",
    "        best_depth,\n",
    "        best_width,\n",
    "        len(class_names),\n",
    "        dropout_rate=dropout_rate,\n",
    "        base_filters=best_filter,\n",
    "    )\n",
    "\n",
    "    # Print architecture\n",
    "    print(f\"\\nArchitecture Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Train and evaluate\n",
    "    result = evaluate_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        X_val,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        f\"CNN Dropout {dropout_rate}\",\n",
    "        epochs=30,\n",
    "    )\n",
    "    result[\"dropout_rate\"] = dropout_rate\n",
    "    dropout_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a5f35",
   "metadata": {},
   "source": [
    "### Experiment 4: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare dropout experiment results\n",
    "dropout_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Dropout Rate\": [r[\"dropout_rate\"] for r in dropout_results],\n",
    "        \"Model\": [r[\"model_name\"] for r in dropout_results],\n",
    "        \"Val Accuracy\": [f\"{r['accuracy']:.4f}\" for r in dropout_results],\n",
    "        \"Val Precision\": [f\"{r['precision']:.4f}\" for r in dropout_results],\n",
    "        \"Val Recall\": [f\"{r['recall']:.4f}\" for r in dropout_results],\n",
    "        \"Val F1-Score\": [f\"{r['f1']:.4f}\" for r in dropout_results],\n",
    "        \"Train Time (s)\": [f\"{r['train_time']:.2f}\" for r in dropout_results],\n",
    "        \"Predict Time (s)\": [f\"{r['predict_time']:.2f}\" for r in dropout_results],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Experiment 4: Dropout Regularization Results\")\n",
    "display(dropout_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Experiment 4 results to CSV\n",
    "dropout_summary.to_csv(\"results/results_experiment4_dropout.csv\", index=False)\n",
    "print(\"\\nResults saved to: results_experiment4_dropout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163362eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dropout experiment results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "dropout_rates = [r[\"dropout_rate\"] for r in dropout_results]\n",
    "dropout_f1 = [r[\"f1\"] for r in dropout_results]\n",
    "dropout_accuracy = [r[\"accuracy\"] for r in dropout_results]\n",
    "dropout_train_time = [r[\"train_time\"] for r in dropout_results]\n",
    "\n",
    "# F1-Score vs Dropout\n",
    "axes[0, 0].plot(dropout_rates, dropout_f1, marker=\"o\", linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel(\"Dropout Rate\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_ylabel(\"F1-Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_title(\"F1-Score vs Dropout Rate\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "axes[0, 0].set_xticks(dropout_rates)\n",
    "\n",
    "# Accuracy vs Dropout\n",
    "axes[0, 1].plot(\n",
    "    dropout_rates,\n",
    "    dropout_accuracy,\n",
    "    marker=\"s\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"green\",\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Dropout Rate\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_ylabel(\"Accuracy\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_title(\"Accuracy vs Dropout Rate\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "axes[0, 1].set_xticks(dropout_rates)\n",
    "\n",
    "# Training Time vs Dropout\n",
    "x_pos = np.arange(len(dropout_rates))\n",
    "axes[1, 0].bar(\n",
    "    x_pos,\n",
    "    dropout_train_time,\n",
    "    color=\"coral\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Dropout Rate\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_ylabel(\"Training Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_title(\"Training Time vs Dropout Rate\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 0].grid(axis=\"y\", alpha=0.3)\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(dropout_rates)\n",
    "\n",
    "# All metrics comparison\n",
    "x = np.arange(len(dropout_rates))\n",
    "width = 0.2\n",
    "axes[1, 1].bar(x - width, dropout_accuracy, width, label=\"Accuracy\")\n",
    "axes[1, 1].bar(x, [r[\"precision\"] for r in dropout_results], width, label=\"Precision\")\n",
    "axes[1, 1].bar(x + width, [r[\"recall\"] for r in dropout_results], width, label=\"Recall\")\n",
    "axes[1, 1].set_xlabel(\"Dropout Rate\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_title(\"Metrics Comparison by Dropout\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(dropout_rates)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aef95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for all dropout configurations\n",
    "for result in dropout_results:\n",
    "    print(f\"\\nTraining Curves for: {result['model_name']}\")\n",
    "    plot_training_curves(result[\"history\"], result[\"model_name\"])\n",
    "\n",
    "# Find best dropout based on F1-Score\n",
    "best_dropout_idx = np.argmax([r[\"f1\"] for r in dropout_results])\n",
    "best_dropout = dropout_results[best_dropout_idx][\"dropout_rate\"]\n",
    "best_dropout_f1 = dropout_results[best_dropout_idx][\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3383aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBest dropout rate      : {best_dropout}\")\n",
    "print(f\"Best F1-Score          : {best_dropout_f1:.4f}\")\n",
    "print(f\"This dropout rate will be used for Experiment 5 (L2 Regularization).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121d52a",
   "metadata": {},
   "source": [
    "## Experiment 5: L2 Regularization\n",
    "\n",
    "In this experiment, we investigate the impact of L2 regularization on the convolutional and dense layers.\n",
    "\n",
    "Using the optimal architecture and best dropout rate, we test different L2 regularization strengths: **0.0 (no L2), 0.0001, 0.001, 0.01**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a78467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_l2_model(\n",
    "    num_blocks,\n",
    "    convs_per_block,\n",
    "    num_classes,\n",
    "    dropout_rate=0.3,\n",
    "    l2_strength=0.001,\n",
    "    input_shape=(64, 64, 3),\n",
    "    base_filters=32,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a CNN with L2 regularization.\n",
    "    Doubles the number of filters after each MaxPooling layer.\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of blocks\n",
    "        convs_per_block: Number of Conv2D layers per block\n",
    "        num_classes: Number of output classes\n",
    "        dropout_rate: Dropout rate\n",
    "        l2_strength: L2 regularization strength (0.0 = no L2)\n",
    "        input_shape: Shape of input images\n",
    "        base_filters: Base number of filters in the first block\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential(name=f\"l2_model_l2{l2_strength}\")\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "    for block in range(num_blocks):\n",
    "        # Calculate number of filters for this block (doubles after each pooling)\n",
    "        current_filters = base_filters * (2**block)\n",
    "\n",
    "        for conv in range(convs_per_block):\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_pre\")\n",
    "            )\n",
    "\n",
    "            # Add L2 regularization to Conv2D\n",
    "            if l2_strength > 0:\n",
    "                model.add(\n",
    "                    layers.Conv2D(\n",
    "                        current_filters,\n",
    "                        (3, 3),\n",
    "                        activation=\"elu\",\n",
    "                        padding=\"same\",\n",
    "                        kernel_initializer=\"he_normal\",\n",
    "                        kernel_regularizer=regularizers.l2(l2_strength),\n",
    "                        name=f\"block{block+1}_conv{conv+1}\",\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                model.add(\n",
    "                    layers.Conv2D(\n",
    "                        current_filters,\n",
    "                        (3, 3),\n",
    "                        activation=\"elu\",\n",
    "                        padding=\"same\",\n",
    "                        kernel_initializer=\"he_normal\",\n",
    "                        name=f\"block{block+1}_conv{conv+1}\",\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            model.add(\n",
    "                layers.BatchNormalization(name=f\"block{block+1}_conv{conv+1}_bn_post\")\n",
    "            )\n",
    "\n",
    "        model.add(layers.MaxPooling2D((2, 2), name=f\"block{block+1}_maxpool\"))\n",
    "\n",
    "        if dropout_rate > 0:\n",
    "            model.add(layers.Dropout(dropout_rate, name=f\"block{block+1}_dropout\"))\n",
    "\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "\n",
    "    if dropout_rate > 0:\n",
    "        model.add(layers.Dropout(dropout_rate, name=\"flatten_dropout\"))\n",
    "\n",
    "    # Add L2 regularization to Dense layers\n",
    "    if l2_strength > 0:\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                128,\n",
    "                activation=\"elu\",\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(l2_strength),\n",
    "                name=\"dense_1\",\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_1\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(layers.BatchNormalization(name=\"dense_1_bn\"))\n",
    "\n",
    "    if l2_strength > 0:\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                128,\n",
    "                activation=\"elu\",\n",
    "                kernel_initializer=\"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(l2_strength),\n",
    "                name=\"dense_2\",\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                128, activation=\"elu\", kernel_initializer=\"he_normal\", name=\"dense_2\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(layers.BatchNormalization(name=\"dense_2_bn\"))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[SparseF1Score(num_classes=num_classes, average=\"weighted\")],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac257ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different L2 regularization strengths\n",
    "l2_configs = [0.0, 0.0001, 0.001, 0.01]\n",
    "l2_results = []\n",
    "\n",
    "print(\n",
    "    f\"Using optimal architecture: {best_depth} blocks, {best_width} convs/block, {best_filter} base filters\"\n",
    ")\n",
    "print(f\"Using best dropout rate: {best_dropout}\")\n",
    "\n",
    "for l2_strength in l2_configs:\n",
    "    print(f\"Testing CNN with L2 regularization: {l2_strength}\")\n",
    "\n",
    "    # Build model\n",
    "    model = build_l2_model(\n",
    "        best_depth,\n",
    "        best_width,\n",
    "        len(class_names),\n",
    "        dropout_rate=best_dropout,\n",
    "        l2_strength=l2_strength,\n",
    "        base_filters=best_filter,\n",
    "    )\n",
    "\n",
    "    # Print architecture\n",
    "    print(f\"\\nArchitecture Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Train and evaluate\n",
    "    result = evaluate_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        X_val,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        f\"CNN L2 {l2_strength}\",\n",
    "        epochs=30,\n",
    "    )\n",
    "    result[\"l2_strength\"] = l2_strength\n",
    "    l2_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b964c9",
   "metadata": {},
   "source": [
    "### Experiment 5: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare L2 experiment results\n",
    "l2_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"L2 Strength\": [r[\"l2_strength\"] for r in l2_results],\n",
    "        \"Model\": [r[\"model_name\"] for r in l2_results],\n",
    "        \"Val Accuracy\": [f\"{r['accuracy']:.4f}\" for r in l2_results],\n",
    "        \"Val Precision\": [f\"{r['precision']:.4f}\" for r in l2_results],\n",
    "        \"Val Recall\": [f\"{r['recall']:.4f}\" for r in l2_results],\n",
    "        \"Val F1-Score\": [f\"{r['f1']:.4f}\" for r in l2_results],\n",
    "        \"Train Time (s)\": [f\"{r['train_time']:.2f}\" for r in l2_results],\n",
    "        \"Predict Time (s)\": [f\"{r['predict_time']:.2f}\" for r in l2_results],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Experiment 5: L2 Regularization Results\")\n",
    "display(l2_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d28b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Experiment 5 results to CSV\n",
    "l2_summary.to_csv(\"results/results_experiment5_l2.csv\", index=False)\n",
    "print(\"\\nResults saved to: results_experiment5_l2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c474e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize L2 experiment results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "l2_strengths = [r[\"l2_strength\"] for r in l2_results]\n",
    "l2_f1 = [r[\"f1\"] for r in l2_results]\n",
    "l2_accuracy = [r[\"accuracy\"] for r in l2_results]\n",
    "l2_train_time = [r[\"train_time\"] for r in l2_results]\n",
    "\n",
    "# F1-Score vs L2\n",
    "axes[0, 0].plot(l2_strengths, l2_f1, marker=\"o\", linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel(\"L2 Regularization Strength\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_ylabel(\"F1-Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_title(\"F1-Score vs L2 Strength\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "axes[0, 0].set_xscale(\"log\")\n",
    "\n",
    "# Accuracy vs L2\n",
    "axes[0, 1].plot(\n",
    "    l2_strengths,\n",
    "    l2_accuracy,\n",
    "    marker=\"s\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"green\",\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"L2 Regularization Strength\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_ylabel(\"Accuracy\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_title(\"Accuracy vs L2 Strength\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "axes[0, 1].set_xscale(\"log\")\n",
    "\n",
    "# Training Time vs L2\n",
    "x_pos = np.arange(len(l2_strengths))\n",
    "axes[1, 0].bar(\n",
    "    x_pos,\n",
    "    l2_train_time,\n",
    "    color=\"coral\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"L2 Regularization Strength\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_ylabel(\"Training Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_title(\"Training Time vs L2 Strength\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 0].grid(axis=\"y\", alpha=0.3)\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(l2_strengths)\n",
    "\n",
    "# All metrics comparison\n",
    "x = np.arange(len(l2_strengths))\n",
    "width = 0.2\n",
    "axes[1, 1].bar(x - width, l2_accuracy, width, label=\"Accuracy\")\n",
    "axes[1, 1].bar(x, [r[\"precision\"] for r in l2_results], width, label=\"Precision\")\n",
    "axes[1, 1].bar(x + width, [r[\"recall\"] for r in l2_results], width, label=\"Recall\")\n",
    "axes[1, 1].set_xlabel(\"L2 Regularization Strength\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_title(\"Metrics Comparison by L2\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(l2_strengths)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for all L2 configurations\n",
    "for result in l2_results:\n",
    "    print(f\"\\nTraining Curves for: {result['model_name']}\")\n",
    "    plot_training_curves(result[\"history\"], result[\"model_name\"])\n",
    "\n",
    "# Find best L2 based on F1-Score\n",
    "best_l2_idx = np.argmax([r[\"f1\"] for r in l2_results])\n",
    "best_l2 = l2_results[best_l2_idx][\"l2_strength\"]\n",
    "best_l2_f1 = l2_results[best_l2_idx][\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36199f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBest L2 strength       : {best_l2}\")\n",
    "print(f\"Best F1-Score          : {best_l2_f1:.4f}\")\n",
    "print(f\"This L2 strength will be used for the final model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fe5aa",
   "metadata": {},
   "source": [
    "## Experiment 6: Data Augmentation with Class Balancing\n",
    "\n",
    "In this experiment, we apply data augmentation to balance all classes to 3000 samples each and investigate the impact on model performance.\n",
    "\n",
    "We use random transformations (rotation, flip, zoom, shift) to augment smaller classes using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8507fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    \"\"\"Apply random augmentation to an image using TensorFlow.\"\"\"\n",
    "    # Convert numpy array to tensor if needed\n",
    "    img = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "\n",
    "    # Random horizontal flip\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "\n",
    "    # Random vertical flip\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "\n",
    "    # Random brightness adjustment\n",
    "    img = tf.image.random_brightness(img, max_delta=0.1)\n",
    "\n",
    "    # Random contrast adjustment\n",
    "    img = tf.image.random_contrast(img, lower=0.9, upper=1.1)\n",
    "\n",
    "    # Random zoom and translation using crop and resize\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    # Random crop size between 90% and 100% of original\n",
    "    crop_factor = tf.random.uniform([], 0.9, 1.0)\n",
    "    new_height = tf.cast(tf.cast(height, tf.float32) * crop_factor, tf.int32)\n",
    "    new_width = tf.cast(tf.cast(width, tf.float32) * crop_factor, tf.int32)\n",
    "    img = tf.image.random_crop(img, [new_height, new_width, 3])\n",
    "    img = tf.image.resize(img, [height, width])\n",
    "\n",
    "    # Random rotation using TensorFlow operations (approximation using flip and transpose)\n",
    "    # For more complex rotations, we can use simple 90-degree rotations\n",
    "    k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
    "    img = tf.image.rot90(img, k=k)\n",
    "    # Ensure output shape is correct\n",
    "    img = tf.image.resize(img, [height, width])\n",
    "\n",
    "    # Clip values to [0, 1]\n",
    "    img = tf.clip_by_value(img, 0.0, 1.0)\n",
    "\n",
    "    return img.numpy()\n",
    "\n",
    "\n",
    "def balance_dataset(X, y, target_samples=3000):\n",
    "    \"\"\"Balance dataset by augmenting minority classes to target_samples.\"\"\"\n",
    "    print(f\"\\nBalancing dataset to {target_samples} samples per class...\")\n",
    "\n",
    "    # Check current class distribution\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    print(\"\\nOriginal class distribution:\")\n",
    "    for cls, count in zip(unique_classes, class_counts):\n",
    "        print(f\"  Class {cls} ({class_names[cls]:20s}): {count:5d} samples\")\n",
    "\n",
    "    X_balanced = []\n",
    "    y_balanced = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Get samples for this class\n",
    "        class_indices = np.where(y == cls)[0]\n",
    "        class_samples = X[class_indices]\n",
    "        current_count = len(class_samples)\n",
    "\n",
    "        # Add original samples\n",
    "        X_balanced.extend(class_samples)\n",
    "        y_balanced.extend([cls] * current_count)\n",
    "\n",
    "        # Augment if needed\n",
    "        if current_count < target_samples:\n",
    "            needed = target_samples - current_count\n",
    "            print(\n",
    "                f\"\\nAugmenting class {cls} ({class_names[cls]}): adding {needed} samples\"\n",
    "            )\n",
    "\n",
    "            for _ in range(needed):\n",
    "                # Randomly select an image from this class\n",
    "                idx = np.random.randint(0, current_count)\n",
    "                original_img = class_samples[idx]\n",
    "\n",
    "                # Augment it\n",
    "                augmented_img = augment_image(original_img)\n",
    "\n",
    "                X_balanced.append(augmented_img)\n",
    "                y_balanced.append(cls)\n",
    "        elif current_count > target_samples:\n",
    "            # Optionally downsample\n",
    "            print(\n",
    "                f\"\\nClass {cls} ({class_names[cls]}) has {current_count} samples (no downsampling)\"\n",
    "            )\n",
    "\n",
    "    X_balanced = np.array(X_balanced)\n",
    "    y_balanced = np.array(y_balanced)\n",
    "\n",
    "    # Check new distribution\n",
    "    unique_classes, class_counts = np.unique(y_balanced, return_counts=True)\n",
    "    print(\"Balanced class distribution:\")\n",
    "    for cls, count in zip(unique_classes, class_counts):\n",
    "        print(f\"  Class {cls} ({class_names[cls]:20s}): {count:5d} samples\")\n",
    "\n",
    "    print(f\"\\nTotal samples: {len(X_balanced)}\")\n",
    "\n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6028639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the training set\n",
    "X_train_balanced, y_train_balanced = balance_dataset(\n",
    "    X_train, y_train, target_samples=3000\n",
    ")\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "indices = np.random.permutation(len(X_train_balanced))\n",
    "X_train_balanced = X_train_balanced[indices]\n",
    "y_train_balanced = y_train_balanced[indices]\n",
    "\n",
    "print(f\"\\nBalanced training set shape: {X_train_balanced.shape}\")\n",
    "print(f\"Balanced labels shape: {y_train_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with balanced dataset\n",
    "print(\"Training CNN with Balanced Dataset + Data Augmentation\")\n",
    "\n",
    "model_augmented = build_l2_model(\n",
    "    best_depth,\n",
    "    best_width,\n",
    "    len(class_names),\n",
    "    dropout_rate=best_dropout,\n",
    "    l2_strength=best_l2,\n",
    "    base_filters=best_filter,\n",
    ")\n",
    "\n",
    "print(f\"\\nArchitecture Summary:\")\n",
    "model_augmented.summary()\n",
    "\n",
    "# Train and evaluate\n",
    "result_augmented = evaluate_model(\n",
    "    model_augmented,\n",
    "    X_train_balanced,\n",
    "    X_val,\n",
    "    y_train_balanced,\n",
    "    y_val,\n",
    "    \"CNN with Data Augmentation\",\n",
    "    epochs=30,\n",
    ")\n",
    "\n",
    "print(\"Data Augmentation Results:\")\n",
    "print(f\"  F1-Score (validation)  : {result_augmented['f1']:.4f}\")\n",
    "print(f\"  Accuracy (validation)  : {result_augmented['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76789a",
   "metadata": {},
   "source": [
    "### Experiment 6: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare augmented vs best L2 model (baseline without augmentation)\n",
    "augmentation_results = [l2_results[best_l2_idx], result_augmented]\n",
    "\n",
    "augmentation_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [r[\"model_name\"] for r in augmentation_results],\n",
    "        \"Val Accuracy\": [f\"{r['accuracy']:.4f}\" for r in augmentation_results],\n",
    "        \"Val Precision\": [f\"{r['precision']:.4f}\" for r in augmentation_results],\n",
    "        \"Val Recall\": [f\"{r['recall']:.4f}\" for r in augmentation_results],\n",
    "        \"Val F1-Score\": [f\"{r['f1']:.4f}\" for r in augmentation_results],\n",
    "        \"Train Time (s)\": [f\"{r['train_time']:.2f}\" for r in augmentation_results],\n",
    "        \"Predict Time (s)\": [f\"{r['predict_time']:.2f}\" for r in augmentation_results],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Experiment 6: Data Augmentation vs Baseline\")\n",
    "display(augmentation_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdaff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Experiment 6 results to CSV\n",
    "augmentation_summary.to_csv(\"results/results_experiment6_augmentation.csv\", index=False)\n",
    "print(\"\\nResults saved to: results_experiment6_augmentation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate improvement\n",
    "f1_improvement = (result_augmented[\"f1\"] - l2_results[best_l2_idx][\"f1\"]) * 100\n",
    "accuracy_improvement = (\n",
    "    result_augmented[\"accuracy\"] - l2_results[best_l2_idx][\"accuracy\"]\n",
    ") * 100\n",
    "\n",
    "print(f\"\\nImprovement with Data Augmentation:\")\n",
    "print(f\"  F1-Score improvement   : {f1_improvement:+.2f}%\")\n",
    "print(f\"  Accuracy improvement   : {accuracy_improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d05450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison between baseline and augmented model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "models = [\"Baseline (Best L2)\", \"With Data Augmentation\"]\n",
    "metrics_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "baseline_metrics = [\n",
    "    l2_results[best_l2_idx][\"accuracy\"],\n",
    "    l2_results[best_l2_idx][\"precision\"],\n",
    "    l2_results[best_l2_idx][\"recall\"],\n",
    "    l2_results[best_l2_idx][\"f1\"],\n",
    "]\n",
    "\n",
    "augmented_metrics = [\n",
    "    result_augmented[\"accuracy\"],\n",
    "    result_augmented[\"precision\"],\n",
    "    result_augmented[\"recall\"],\n",
    "    result_augmented[\"f1\"],\n",
    "]\n",
    "\n",
    "# Metrics comparison\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "axes[0].bar(x - width / 2, baseline_metrics, width, label=\"Baseline\", alpha=0.8)\n",
    "axes[0].bar(\n",
    "    x + width / 2, augmented_metrics, width, label=\"With Augmentation\", alpha=0.8\n",
    ")\n",
    "axes[0].set_xlabel(\"Metrics\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\n",
    "    \"Baseline vs Data Augmentation - All Metrics\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_names)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "axes[0].set_ylim([0.8, 1.0])\n",
    "\n",
    "# Training time comparison\n",
    "train_times = [l2_results[best_l2_idx][\"train_time\"], result_augmented[\"train_time\"]]\n",
    "axes[1].bar(\n",
    "    models, train_times, color=[\"coral\", \"steelblue\"], edgecolor=\"black\", alpha=0.8\n",
    ")\n",
    "axes[1].set_ylabel(\"Training Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"Training Time Comparison\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves comparison\n",
    "print(\"\\nTraining Curves - Baseline (Best L2 Model):\")\n",
    "plot_training_curves(\n",
    "    l2_results[best_l2_idx][\"history\"], l2_results[best_l2_idx][\"model_name\"]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Curves - With Data Augmentation:\")\n",
    "plot_training_curves(result_augmented[\"history\"], result_augmented[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da2df9",
   "metadata": {},
   "source": [
    "## Experiment 7: Batch Size\n",
    "\n",
    "In this experiment, we investigate the impact of different batch sizes on model performance.\n",
    "\n",
    "Using the optimal architecture from previous experiments, we test different batch sizes: **16, 32, 64, and 128**. We use the best hyperparameters found in previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6929249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch_size_model(\n",
    "    num_blocks,\n",
    "    convs_per_block,\n",
    "    num_classes,\n",
    "    dropout_rate,\n",
    "    l2_strength,\n",
    "    base_filters,\n",
    "    batch_size,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a CNN for batch size experiments.\n",
    "    Doubles the number of filters after each MaxPooling layer.\n",
    "\n",
    "    Args:\n",
    "        num_blocks: Number of blocks\n",
    "        convs_per_block: Number of Conv2D layers per block\n",
    "        num_classes: Number of output classes\n",
    "        dropout_rate: Dropout rate\n",
    "        l2_strength: L2 regularization strength\n",
    "        base_filters: Base number of filters in the first block\n",
    "        batch_size: Batch size (used for model naming)\n",
    "\n",
    "    Returns:\n",
    "        Keras model (uncompiled)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=f\"batch_model_{batch_size}\")\n",
    "    model.add(keras.layers.Input(shape=(64, 64, 3)))\n",
    "\n",
    "    for block in range(num_blocks):\n",
    "        # Calculate number of filters for this block (doubles after each pooling)\n",
    "        current_filters = base_filters * (2**block)\n",
    "\n",
    "        for conv in range(convs_per_block):\n",
    "            # Batch Normalization before convolution\n",
    "            model.add(\n",
    "                keras.layers.BatchNormalization(\n",
    "                    name=f\"block{block+1}_conv{conv+1}_bn_pre\"\n",
    "                )\n",
    "            )\n",
    "            # Convolutional layer\n",
    "            model.add(\n",
    "                keras.layers.Conv2D(\n",
    "                    current_filters,\n",
    "                    (3, 3),\n",
    "                    activation=\"elu\",\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=keras.regularizers.l2(l2_strength),\n",
    "                    name=f\"block{block+1}_conv{conv+1}\",\n",
    "                )\n",
    "            )\n",
    "            # Batch Normalization after convolution\n",
    "            model.add(\n",
    "                keras.layers.BatchNormalization(\n",
    "                    name=f\"block{block+1}_conv{conv+1}_bn_post\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # MaxPooling after each block\n",
    "        model.add(\n",
    "            keras.layers.MaxPooling2D(pool_size=(2, 2), name=f\"block{block+1}_maxpool\")\n",
    "        )\n",
    "        # Dropout after each block\n",
    "        model.add(keras.layers.Dropout(dropout_rate, name=f\"block{block+1}_dropout\"))\n",
    "\n",
    "    # Flatten and Dense layers\n",
    "    model.add(keras.layers.Flatten(name=\"flatten\"))\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            128,\n",
    "            activation=\"elu\",\n",
    "            kernel_regularizer=keras.regularizers.l2(l2_strength),\n",
    "            name=\"dense_1\",\n",
    "        )\n",
    "    )\n",
    "    model.add(keras.layers.BatchNormalization(name=\"dense_1_bn\"))\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            128,\n",
    "            activation=\"elu\",\n",
    "            kernel_regularizer=keras.regularizers.l2(l2_strength),\n",
    "            name=\"dense_2\",\n",
    "        )\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(dropout_rate, name=\"dense_dropout\"))\n",
    "    model.add(keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different batch sizes\n",
    "batch_size_configs = [16, 32, 64, 128]\n",
    "batch_size_results = []\n",
    "\n",
    "print(\n",
    "    f\"Using optimal architecture: {best_depth} blocks, {best_width} convs/block, {best_filter} base filters\"\n",
    ")\n",
    "print(f\"Using best dropout: {best_dropout}, best L2: {best_l2}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for batch_size in batch_size_configs:\n",
    "    print(f\"\\nTesting CNN with batch size: {batch_size}\")\n",
    "\n",
    "    # Build model with proper naming\n",
    "    model = build_batch_size_model(\n",
    "        best_depth,\n",
    "        best_width,\n",
    "        len(class_names),\n",
    "        dropout_rate=best_dropout,\n",
    "        l2_strength=best_l2,\n",
    "        base_filters=best_filter,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # Evaluate model with specific batch size\n",
    "    result = evaluate_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        model_name=f\"CNN Batch {batch_size}\",\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # Add batch_size to result dictionary\n",
    "    result[\"batch_size\"] = batch_size\n",
    "    batch_size_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9086b6b",
   "metadata": {},
   "source": [
    "### Experiment 7: Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce479afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare batch size experiment results in a table\n",
    "batch_size_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Batch Size\": [r[\"batch_size\"] for r in batch_size_results],\n",
    "        \"Model\": [r[\"model_name\"] for r in batch_size_results],\n",
    "        \"Val Accuracy\": [f\"{r['accuracy']:.4f}\" for r in batch_size_results],\n",
    "        \"Val Precision\": [f\"{r['precision']:.4f}\" for r in batch_size_results],\n",
    "        \"Val Recall\": [f\"{r['recall']:.4f}\" for r in batch_size_results],\n",
    "        \"Val F1-Score\": [f\"{r['f1']:.4f}\" for r in batch_size_results],\n",
    "        \"Train Time (s)\": [f\"{r['train_time']:.2f}\" for r in batch_size_results],\n",
    "        \"Predict Time (s)\": [f\"{r['predict_time']:.2f}\" for r in batch_size_results],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Experiment 7: Batch Size Optimization Results\")\n",
    "display(batch_size_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652440b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Experiment 7 results to CSV\n",
    "batch_size_summary.to_csv(\"results/results_experiment7_batch_size.csv\", index=False)\n",
    "print(\"\\nResults saved to: results_experiment7_batch_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize batch size experiment results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "batch_sizes = [r[\"batch_size\"] for r in batch_size_results]\n",
    "batch_f1 = [r[\"f1\"] for r in batch_size_results]\n",
    "batch_accuracy = [r[\"accuracy\"] for r in batch_size_results]\n",
    "batch_train_time = [r[\"train_time\"] for r in batch_size_results]\n",
    "\n",
    "# F1-Score vs Batch Size\n",
    "axes[0, 0].plot(\n",
    "    batch_sizes,\n",
    "    batch_f1,\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"Batch Size\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_ylabel(\"F1-Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].set_title(\"F1-Score vs Batch Size\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "axes[0, 0].set_xscale(\"log\", base=2)\n",
    "axes[0, 0].set_xticks(batch_sizes)\n",
    "axes[0, 0].set_xticklabels(batch_sizes)\n",
    "\n",
    "# Accuracy vs Batch Size\n",
    "axes[0, 1].plot(\n",
    "    batch_sizes,\n",
    "    batch_accuracy,\n",
    "    marker=\"s\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"green\",\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Batch Size\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_ylabel(\"Accuracy\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].set_title(\"Accuracy vs Batch Size\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "axes[0, 1].set_xscale(\"log\", base=2)\n",
    "axes[0, 1].set_xticks(batch_sizes)\n",
    "axes[0, 1].set_xticklabels(batch_sizes)\n",
    "\n",
    "# Training Time vs Batch Size\n",
    "x_pos = np.arange(len(batch_sizes))\n",
    "axes[1, 0].bar(\n",
    "    x_pos,\n",
    "    batch_train_time,\n",
    "    color=\"coral\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Batch Size\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_ylabel(\"Training Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].set_title(\"Training Time vs Batch Size\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 0].grid(axis=\"y\", alpha=0.3)\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(batch_sizes)\n",
    "\n",
    "# All metrics comparison\n",
    "x = np.arange(len(batch_sizes))\n",
    "width = 0.2\n",
    "axes[1, 1].bar(x - width, batch_accuracy, width, label=\"Accuracy\")\n",
    "axes[1, 1].bar(\n",
    "    x, [r[\"precision\"] for r in batch_size_results], width, label=\"Precision\"\n",
    ")\n",
    "axes[1, 1].bar(\n",
    "    x + width, [r[\"recall\"] for r in batch_size_results], width, label=\"Recall\"\n",
    ")\n",
    "axes[1, 1].set_xlabel(\"Batch Size\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_ylabel(\"Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].set_title(\"Metrics Comparison by Batch Size\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(batch_sizes)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for all batch size configurations\n",
    "for result in batch_size_results:\n",
    "    print(f\"\\nTraining Curves for: {result['model_name']}\")\n",
    "    plot_training_curves(result[\"history\"], result[\"model_name\"])\n",
    "\n",
    "# Find best batch size based on F1-Score\n",
    "best_batch_idx = np.argmax([r[\"f1\"] for r in batch_size_results])\n",
    "best_batch_size = batch_size_results[best_batch_idx][\"batch_size\"]\n",
    "best_batch_f1 = batch_size_results[best_batch_idx][\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBest batch size        : {best_batch_size}\")\n",
    "print(f\"Best F1-Score          : {best_batch_f1:.4f}\")\n",
    "print(f\"This batch size provides optimal training efficiency and performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf93f846",
   "metadata": {},
   "source": [
    "## Best Model Selection and Final Evaluation\n",
    "\n",
    "Now we select the best model from all experiments (1-7) and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all experiment results\n",
    "all_results = {\n",
    "    \"Depth Experiments\": depth_results,\n",
    "    \"Width Experiments\": width_results,\n",
    "    \"Filter Experiments\": filter_results,\n",
    "    \"Dropout Experiments\": dropout_results,\n",
    "    \"L2 Experiments\": l2_results,\n",
    "    \"Augmented Model\": [result_augmented],\n",
    "    \"Batch Size Experiments\": batch_size_results,\n",
    "}\n",
    "\n",
    "# Find best model overall\n",
    "best_f1_overall = 0\n",
    "best_model_name = \"\"\n",
    "best_experiment = \"\"\n",
    "\n",
    "for exp_name, results in all_results.items():\n",
    "    for result in results:\n",
    "        if result[\"f1\"] > best_f1_overall:\n",
    "            best_f1_overall = result[\"f1\"]\n",
    "            best_model_name = result[\"model_name\"]\n",
    "            best_experiment = exp_name\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"From Experiment: {best_experiment}\")\n",
    "print(f\"Validation F1-Score: {best_f1_overall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model configuration on full training data (including validation)\n",
    "print(\"Training Best Model on Full Training Set\")\n",
    "\n",
    "# Combine training and validation sets\n",
    "X_train_full = np.concatenate([X_train, X_val])\n",
    "y_train_full = np.concatenate([y_train, y_val])\n",
    "\n",
    "print(f\"\\nFull training set size: {X_train_full.shape[0]} samples\")\n",
    "\n",
    "# Determine best batch size to use\n",
    "if best_experiment == \"Batch Size Experiments\":\n",
    "    use_batch_size = best_batch_size\n",
    "    print(f\"Using best batch size from Experiment 7: {use_batch_size}\")\n",
    "else:\n",
    "    use_batch_size = 32\n",
    "    print(f\"Using default batch size: {use_batch_size}\")\n",
    "\n",
    "# Build the best model (using augmented data if it was the best)\n",
    "if best_experiment == \"Augmented Model\":\n",
    "    print(\"\\nUsing balanced dataset with augmentation...\")\n",
    "    X_train_final, y_train_final = balance_dataset(\n",
    "        X_train_full, y_train_full, target_samples=3000\n",
    "    )\n",
    "\n",
    "    # Shuffle\n",
    "    indices = np.random.permutation(len(X_train_final))\n",
    "    X_train_final = X_train_final[indices]\n",
    "    y_train_final = y_train_final[indices]\n",
    "else:\n",
    "    X_train_final = X_train_full\n",
    "    y_train_final = y_train_full\n",
    "\n",
    "# Build final model with best hyperparameters\n",
    "final_model = build_l2_model(\n",
    "    best_depth,\n",
    "    best_width,\n",
    "    len(class_names),\n",
    "    dropout_rate=best_dropout,\n",
    "    l2_strength=best_l2,\n",
    "    base_filters=best_filter,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Model Architecture:\")\n",
    "final_model.summary()\n",
    "\n",
    "# Train without validation split (using all training data)\n",
    "print(f\"\\nTraining final model with batch size {use_batch_size}...\")\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=7,\n",
    "    restore_best_weights=True,\n",
    "    mode=\"min\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    X_train_final,\n",
    "    y_train_final,\n",
    "    batch_size=use_batch_size,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model on test set\n",
    "print(\"Final Model Evaluation on Test Set\")\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred_probs = final_model.predict(X_test, verbose=0)\n",
    "y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average=\"weighted\")\n",
    "test_recall = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  Accuracy             : {test_accuracy:.4f}\")\n",
    "print(f\"  Precision            : {test_precision:.4f}\")\n",
    "print(f\"  Recall               : {test_recall:.4f}\")\n",
    "print(f\"  F1-Score             : {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(f\"\\nConfusion Matrix (Test Set):\")\n",
    "cm_test = plot_confusion_matrix(\n",
    "    y_test, y_test_pred, class_names, \"Final Model - Test Set\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2397007b",
   "metadata": {},
   "source": [
    "## Experiment 8: Transfer Learning\n",
    "\n",
    "In this experiment, we use pre-trained models (ResNet50 and InceptionV3) with transfer learning to classify EuroSAT images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import (\n",
    "    preprocess_input as inception_preprocess,\n",
    ")\n",
    "\n",
    "\n",
    "def build_transfer_learning_model(\n",
    "    base_model_name, num_classes, input_shape=(64, 64, 3)\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a transfer learning model using pre-trained base models.\n",
    "\n",
    "    Args:\n",
    "        base_model_name: Name of the base model ('resnet50' or 'inceptionv3')\n",
    "        num_classes: Number of output classes\n",
    "        input_shape: Shape of input images\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    if base_model_name.lower() == \"resnet50\":\n",
    "        base_model = ResNet50(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            pooling=\"avg\",\n",
    "        )\n",
    "    elif base_model_name.lower() == \"inceptionv3\":\n",
    "        base_model = InceptionV3(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            pooling=\"avg\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
    "\n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build the model\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=input_shape),\n",
    "            base_model,\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[SparseF1Score(num_classes=num_classes, average=\"weighted\")],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c36a0e",
   "metadata": {},
   "source": [
    "### ResNet50 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet50 model\n",
    "print(\"Training ResNet50 Model\")\n",
    "\n",
    "resnet_model = build_transfer_learning_model(\"resnet50\", len(class_names))\n",
    "\n",
    "print(f\"\\nResNet50 Model Architecture:\")\n",
    "resnet_model.summary()\n",
    "\n",
    "# Train ResNet50\n",
    "resnet_result = evaluate_model(\n",
    "    resnet_model,\n",
    "    X_train,\n",
    "    X_val,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    \"ResNet50 Transfer Learning\",\n",
    "    epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05735a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ResNet50 Validation Results:\")\n",
    "print(f\"  F1-Score             : {resnet_result['f1']:.4f}\")\n",
    "print(f\"  Accuracy             : {resnet_result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdacae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plot_training_curves(resnet_result[\"history\"], \"ResNet50 Transfer Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27622851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ResNet50 on test set\n",
    "print(\"ResNet50 - Test Set Evaluation\")\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred_resnet_probs = resnet_model.predict(X_test, verbose=0)\n",
    "y_test_pred_resnet = np.argmax(y_test_pred_resnet_probs, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy_resnet = accuracy_score(y_test, y_test_pred_resnet)\n",
    "test_precision_resnet = precision_score(y_test, y_test_pred_resnet, average=\"weighted\")\n",
    "test_recall_resnet = recall_score(y_test, y_test_pred_resnet, average=\"weighted\")\n",
    "test_f1_resnet = f1_score(y_test, y_test_pred_resnet, average=\"weighted\")\n",
    "\n",
    "print(f\"\\nResNet50 Test Set Performance:\")\n",
    "print(f\"  Accuracy             : {test_accuracy_resnet:.4f}\")\n",
    "print(f\"  Precision            : {test_precision_resnet:.4f}\")\n",
    "print(f\"  Recall               : {test_recall_resnet:.4f}\")\n",
    "print(f\"  F1-Score             : {test_f1_resnet:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd03813",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_resnet, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_resnet = plot_confusion_matrix(\n",
    "    y_test, y_test_pred_resnet, class_names, \"ResNet50 - Test Set\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a694e",
   "metadata": {},
   "source": [
    "### InceptionV3 Transfer Learning (GoogLeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build InceptionV3 model\n",
    "print(\"Training InceptionV3 Transfer Learning Model\")\n",
    "\n",
    "inception_model = build_transfer_learning_model(\"inceptionv3\", len(class_names))\n",
    "\n",
    "print(f\"\\nInceptionV3 Model Architecture:\")\n",
    "inception_model.summary()\n",
    "\n",
    "# Train InceptionV3\n",
    "inception_result = evaluate_model(\n",
    "    inception_model,\n",
    "    X_train,\n",
    "    X_val,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    \"InceptionV3 Transfer Learning\",\n",
    "    epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a651bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"InceptionV3 Validation Results:\")\n",
    "print(f\"  F1-Score             : {inception_result['f1']:.4f}\")\n",
    "print(f\"  Accuracy             : {inception_result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plot_training_curves(inception_result[\"history\"], \"InceptionV3 Transfer Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate InceptionV3 on test set\n",
    "print(\"InceptionV3 - Test Set Evaluation\")\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred_inception_probs = inception_model.predict(X_test, verbose=0)\n",
    "y_test_pred_inception = np.argmax(y_test_pred_inception_probs, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy_inception = accuracy_score(y_test, y_test_pred_inception)\n",
    "test_precision_inception = precision_score(\n",
    "    y_test, y_test_pred_inception, average=\"weighted\"\n",
    ")\n",
    "test_recall_inception = recall_score(y_test, y_test_pred_inception, average=\"weighted\")\n",
    "test_f1_inception = f1_score(y_test, y_test_pred_inception, average=\"weighted\")\n",
    "\n",
    "print(f\"\\nInceptionV3 Test Set Performance:\")\n",
    "print(f\"  Accuracy             : {test_accuracy_inception:.4f}\")\n",
    "print(f\"  Precision            : {test_precision_inception:.4f}\")\n",
    "print(f\"  Recall               : {test_recall_inception:.4f}\")\n",
    "print(f\"  F1-Score             : {test_f1_inception:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_inception, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_inception = plot_confusion_matrix(\n",
    "    y_test, y_test_pred_inception, class_names, \"InceptionV3 - Test Set\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbfbe1",
   "metadata": {},
   "source": [
    "## Final Comparison: All Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdacd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models on test set\n",
    "test_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"Custom CNN (Best)\", \"ResNet50\", \"InceptionV3\"],\n",
    "        \"Test Accuracy\": [\n",
    "            f\"{test_accuracy:.4f}\",\n",
    "            f\"{test_accuracy_resnet:.4f}\",\n",
    "            f\"{test_accuracy_inception:.4f}\",\n",
    "        ],\n",
    "        \"Test Precision\": [\n",
    "            f\"{test_precision:.4f}\",\n",
    "            f\"{test_precision_resnet:.4f}\",\n",
    "            f\"{test_precision_inception:.4f}\",\n",
    "        ],\n",
    "        \"Test Recall\": [\n",
    "            f\"{test_recall:.4f}\",\n",
    "            f\"{test_recall_resnet:.4f}\",\n",
    "            f\"{test_recall_inception:.4f}\",\n",
    "        ],\n",
    "        \"Test F1-Score\": [\n",
    "            f\"{test_f1:.4f}\",\n",
    "            f\"{test_f1_resnet:.4f}\",\n",
    "            f\"{test_f1_inception:.4f}\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Final Test Comparison\")\n",
    "display(test_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final test comparison results to CSV\n",
    "test_comparison.to_csv(\"results/results_final_test_comparison.csv\", index=False)\n",
    "print(\"\\nFinal test results saved to: results_final_test_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "models = [\"Custom CNN\", \"ResNet50\", \"InceptionV3\"]\n",
    "test_f1_scores = [test_f1, test_f1_resnet, test_f1_inception]\n",
    "test_accuracies = [test_accuracy, test_accuracy_resnet, test_accuracy_inception]\n",
    "\n",
    "# F1-Score comparison\n",
    "axes[0].bar(\n",
    "    models, test_f1_scores, color=[\"steelblue\", \"coral\", \"green\"], edgecolor=\"black\"\n",
    ")\n",
    "axes[0].set_ylabel(\"F1-Score\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Test Set F1-Score Comparison\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[1].bar(\n",
    "    models, test_accuracies, color=[\"steelblue\", \"coral\", \"green\"], edgecolor=\"black\"\n",
    ")\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"Test Set Accuracy Comparison\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].grid(axis=\"y\", alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fcd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best overall model\n",
    "best_test_f1 = max(test_f1, test_f1_resnet, test_f1_inception)\n",
    "if best_test_f1 == test_f1:\n",
    "    best_overall_model = \"Custom CNN (Best)\"\n",
    "elif best_test_f1 == test_f1_resnet:\n",
    "    best_overall_model = \"ResNet50\"\n",
    "else:\n",
    "    best_overall_model = \"InceptionV3\"\n",
    "\n",
    "print(f\"Best Overall Model on Test Set: {best_overall_model}\")\n",
    "print(f\"Test F1-Score: {best_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc26cd9",
   "metadata": {},
   "source": [
    "## Summary of All Experiments\n",
    "\n",
    "Complete overview of all experiments and their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete Experiment Summary - EuroSAT CNN Architecture Experiments\")\n",
    "\n",
    "print(f\"\\nExperiment 1: Network Depth\")\n",
    "print(f\"  - Configurations tested: {[2, 3, 4, 5]} blocks\")\n",
    "print(f\"  - Best configuration   : {best_depth} blocks\")\n",
    "print(f\"  - Best val F1-Score    : {best_depth_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nExperiment 2: Block Width\")\n",
    "print(f\"  - Configurations tested: {[2, 3, 4]} Conv2D layers per block\")\n",
    "print(f\"  - Best configuration   : {best_width} Conv2D layers per block\")\n",
    "print(f\"  - Best val F1-Score    : {best_width_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nExperiment 3: Number of Filters\")\n",
    "print(f\"  - Configurations tested: {[16, 32, 64, 128]} base filters\")\n",
    "print(f\"  - Best configuration   : {best_filter} base filters\")\n",
    "print(f\"  - Best val F1-Score    : {best_filter_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nExperiment 4: Dropout Regularization\")\n",
    "print(f\"  - Configurations tested: {dropout_configs}\")\n",
    "print(f\"  - Best configuration   : {best_dropout} dropout rate\")\n",
    "print(f\"  - Best val F1-Score    : {best_dropout_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nExperiment 5: L2 Regularization\")\n",
    "print(f\"  - Configurations tested: {l2_configs}\")\n",
    "print(f\"  - Best configuration   : {best_l2} L2 strength\")\n",
    "print(f\"  - Best val F1-Score    : {best_l2_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nExperiment 6: Data Augmentation\")\n",
    "print(f\"  - Balanced classes to  : 3000 samples each\")\n",
    "print(f\"  - Val F1-Score         : {result_augmented['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nExperiment 7: Batch Size Optimization\")\n",
    "print(f\"  - Configurations tested: {batch_size_configs}\")\n",
    "print(f\"  - Best configuration   : {best_batch_size} batch size\")\n",
    "print(f\"  - Best val F1-Score    : {best_batch_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nExperiment 8: Transfer Learning\")\n",
    "print(f\"  - ResNet50 val F1      : {resnet_result['f1']:.4f}\")\n",
    "print(f\"  - InceptionV3 val F1   : {inception_result['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Test Set Results\")\n",
    "print(f\"  Custom CNN    - F1: {test_f1:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "print(\n",
    "    f\"  ResNet50      - F1: {test_f1_resnet:.4f}, Accuracy: {test_accuracy_resnet:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  InceptionV3   - F1: {test_f1_inception:.4f}, Accuracy: {test_accuracy_inception:.4f}\"\n",
    ")\n",
    "print(f\"\\n  Winner: {best_overall_model} with F1-Score: {best_test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eurosat-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b97fd8a",
   "metadata": {},
   "source": [
    "# EuroSAT Baseline Classic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4be6dc",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "import time\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f9fcf8",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eurosat_dataset(data_dir=\"data\"):\n",
    "    data_path = Path(data_dir)\n",
    "\n",
    "    # Get all class directories\n",
    "    class_dirs = [d for d in data_path.iterdir() if d.is_dir()]\n",
    "    class_names = sorted([d.name for d in class_dirs])\n",
    "\n",
    "    print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load images from each class\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = data_path / class_name\n",
    "        image_files = list(class_path.glob(\"*.jpg\")) + list(class_path.glob(\"*.png\"))\n",
    "\n",
    "        print(f\"Loading {len(image_files)} images from {class_name}...\")\n",
    "\n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                # Load image\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Store image and label\n",
    "                images.append(img_array)\n",
    "                labels.append(class_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    data = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"\\nDataset loaded successfully!\")\n",
    "    print(f\"Total images           : {len(data)}\")\n",
    "    print(f\"Data shape             : {data.shape}\")\n",
    "    print(f\"Labels shape           : {labels.shape}\")\n",
    "\n",
    "    return data, labels, class_names\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data, labels, class_names = load_eurosat_dataset(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd65113",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = []\n",
    "\n",
    "    # RGB channel statistics (6 features)\n",
    "    for channel in range(3):\n",
    "        features.append(image[..., channel].mean())  # Mean for R, G, B\n",
    "        features.append(image[..., channel].std())  # Std for R, G, B\n",
    "\n",
    "    # Brightness statistics (2 features)\n",
    "    brightness = 0.299 * image[..., 0] + 0.587 * image[..., 1] + 0.114 * image[..., 2]\n",
    "    features.append(brightness.mean())\n",
    "    features.append(brightness.std())\n",
    "\n",
    "    # Contrast (1 feature)\n",
    "    contrast = image.std()\n",
    "    features.append(contrast)\n",
    "\n",
    "    # Pixel value statistics (3 features)\n",
    "    features.append(image.min())\n",
    "    features.append(image.max())\n",
    "    features.append(np.median(image))\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# Extract features from all images\n",
    "print(\"Extracting features from images...\")\n",
    "start_time = time.time()\n",
    "\n",
    "X = np.array([extract_features(img) for img in data])\n",
    "y = labels\n",
    "\n",
    "end_time = time.time()\n",
    "print(\n",
    "    f\"Feature extraction completed in             : {end_time - start_time:.2f} seconds\"\n",
    ")\n",
    "print(f\"Feature matrix shape                        : {X.shape}\")\n",
    "print(f\"Number of features per image                : {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature statistics\n",
    "feature_names = [\n",
    "    \"R_mean\",\n",
    "    \"R_std\",\n",
    "    \"G_mean\",\n",
    "    \"G_std\",\n",
    "    \"B_mean\",\n",
    "    \"B_std\",\n",
    "    \"brightness_mean\",\n",
    "    \"brightness_std\",\n",
    "    \"contrast\",\n",
    "    \"pixel_min\",\n",
    "    \"pixel_max\",\n",
    "    \"pixel_median\",\n",
    "]\n",
    "\n",
    "feature_df = pd.DataFrame(X, columns=feature_names)\n",
    "print(\"\\nFeature:\")\n",
    "print(feature_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de46347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature statistics:\")\n",
    "print(feature_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ea038",
   "metadata": {},
   "source": [
    "## Data split and feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.13, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set size:          {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size:        {X_val.shape[0]} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(\"\\nFeature scaling completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745409c",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_gridsearch(\n",
    "    model, param_grid, X_train, X_val, y_train, y_val, model_name\n",
    "):\n",
    "    \"\"\"Train model with GridSearchCV and evaluate on validation set\"\"\"\n",
    "\n",
    "    print(f\"Training {model_name} with GridSearchCV...\")\n",
    "    print(f\"Parameter grid: {param_grid}\")\n",
    "\n",
    "    # GridSearchCV with 5-fold cross-validation\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(\n",
    "        model, param_grid, cv=5, scoring=\"f1_weighted\", n_jobs=-1, verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"\\nBest parameters                     : {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score         : {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Training time                       : {train_time:.2f} seconds\")\n",
    "\n",
    "    # Predict on validation set\n",
    "    start_time = time.time()\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    predict_time = time.time() - start_time\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_val, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Prediction time: {predict_time:.2f} seconds\")\n",
    "    print(f\"\\nValidation Set Performance Metrics:\")\n",
    "    print(f\"  Accuracy              : {accuracy:.4f}\")\n",
    "    print(f\"  Precision             : {precision:.4f}\")\n",
    "    print(f\"  Recall                : {recall:.4f}\")\n",
    "    print(f\"  F1-Score              : {f1:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=class_names))\n",
    "\n",
    "    return {\n",
    "        \"model\": best_model,\n",
    "        \"grid_search\": grid_search,\n",
    "        \"model_name\": model_name,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"best_params\": grid_search.best_params_,\n",
    "        \"cv_score\": grid_search.best_score_,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"train_time\": train_time,\n",
    "        \"predict_time\": predict_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e92dc7",
   "metadata": {},
   "source": [
    "### 1. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619bf83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn_param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "}\n",
    "\n",
    "knn_results = evaluate_model_with_gridsearch(\n",
    "    knn, knn_param_grid, X_train_scaled, X_val_scaled, y_train, y_val, \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4367b3",
   "metadata": {},
   "source": [
    "### 2. Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "svc = SVC(random_state=42)\n",
    "svc_param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 100],\n",
    "    \"kernel\": [\"poly\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "svc_results = evaluate_model_with_gridsearch(\n",
    "    svc, svc_param_grid, X_train_scaled, X_val_scaled, y_train, y_val, \"SVC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f07c01",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "rf_results = evaluate_model_with_gridsearch(\n",
    "    rf, rf_param_grid, X_train_scaled, X_val_scaled, y_train, y_val, \"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe84533",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            knn_results[\"model_name\"],\n",
    "            svc_results[\"model_name\"],\n",
    "            rf_results[\"model_name\"],\n",
    "        ],\n",
    "        \"Best Params\": [\n",
    "            str(knn_results[\"best_params\"]),\n",
    "            str(svc_results[\"best_params\"]),\n",
    "            str(rf_results[\"best_params\"]),\n",
    "        ],\n",
    "        \"CV Score\": [\n",
    "            knn_results[\"cv_score\"],\n",
    "            svc_results[\"cv_score\"],\n",
    "            rf_results[\"cv_score\"],\n",
    "        ],\n",
    "        \"Val Accuracy\": [\n",
    "            knn_results[\"accuracy\"],\n",
    "            svc_results[\"accuracy\"],\n",
    "            rf_results[\"accuracy\"],\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            knn_results[\"precision\"],\n",
    "            svc_results[\"precision\"],\n",
    "            rf_results[\"precision\"],\n",
    "        ],\n",
    "        \"Recall\": [knn_results[\"recall\"], svc_results[\"recall\"], rf_results[\"recall\"]],\n",
    "        \"F1-Score\": [knn_results[\"f1\"], svc_results[\"f1\"], rf_results[\"f1\"]],\n",
    "        \"Train Time (s)\": [\n",
    "            knn_results[\"train_time\"],\n",
    "            svc_results[\"train_time\"],\n",
    "            rf_results[\"train_time\"],\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74493ce",
   "metadata": {},
   "source": [
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28bcc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_confusion_matrices(y_val, predictions_dict, class_names):\n",
    "    \"\"\"Plot confusion matrices for all models in a single figure with 3 subplots\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 7))\n",
    "\n",
    "    for idx, (model_name, y_pred) in enumerate(predictions_dict.items()):\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            cbar_kws={\"label\": \"Number of samples\"},\n",
    "            ax=axes[idx],\n",
    "        )\n",
    "        axes[idx].set_xlabel(\"Predicted Label\", fontsize=12, fontweight=\"bold\")\n",
    "        axes[idx].set_ylabel(\"True Label\", fontsize=12, fontweight=\"bold\")\n",
    "        axes[idx].set_title(\n",
    "            f\"Confusion Matrix - {model_name}\", fontsize=14, fontweight=\"bold\"\n",
    "        )\n",
    "        axes[idx].set_xticklabels(axes[idx].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "        axes[idx].set_yticklabels(axes[idx].get_yticklabels(), rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all best models\n",
    "predictions = {\n",
    "    \"KNN (Best Model)\": knn_results[\"y_pred\"],\n",
    "    \"SVC (Best Model)\": svc_results[\"y_pred\"],\n",
    "    \"Random Forest (Best Model)\": rf_results[\"y_pred\"],\n",
    "}\n",
    "\n",
    "plot_all_confusion_matrices(y_val, predictions, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1345226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
